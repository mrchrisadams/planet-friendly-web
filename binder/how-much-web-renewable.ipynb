{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# How much of the web runs on renewable power?\n",
    "\n",
    "I'm trying to work this out as some research for the Planet Friendly Web Guide, as I can't find much info online myself.\n",
    "\n",
    "Here's my current thinking on how you might do this. There are obvious holes in this, but it's a start, and having _something_ publicly accessible presumably better than what we have now, this is _nowt_.\n",
    "\n",
    "\n",
    "## My current thinking about how to do this\n",
    "\n",
    "- Take a dataset that is representative of the entire web, listing the most popular sites\n",
    "- Find a away to tell if these sites are running on renewable power\n",
    "- Run this check on the sites\n",
    "- Share results\n",
    "\n",
    "I'll explain these in more detail.\n",
    "\n",
    "\n",
    "### Find a dataset that's representative\n",
    "\n",
    "Right now, the de-factor dataset used to represent how the web is used, at least for web performance optimisation and marketing is Alexa's list of the top million sites, as described on [the HTTP Archive site][1].\n",
    "\n",
    "[1]: https://httparchive.org/about.php#faq\n",
    "\n",
    "Iniitally I thought you might need to come up with some on Big Query er, query, like described here on [Ilya Grigorik's website](https://www.igvita.com/2013/06/20/http-archive-bigquery-web-performance-answers/). This saves needing to run our own infra, and should make reproducible.\n",
    "\n",
    "But given we only need the url, and rank for now we might be able to do this without needing to learn big query, or how to make API calls when running a query on the BigQuery.\n",
    "\n",
    "The list of the top million is downloadable as a compressed file, that's about 9mb compressed, and 23mb uncompressed. This is downloadable from an Amazon S3 bucket, at the link below\n",
    "\n",
    "http://s3.amazonaws.com/alexa-static/top-1m.csv.zip\n",
    "\n",
    "### Find a way to tell if it's running on renewable power\n",
    "\n",
    "This in itself is a hellishly complex topic - as there loads of ways to declare that your infrastructure is running on renewable power, from _actually using renewables directly_ to using various financial instruments to buy the same about renewable power you're really using in a non-renewably powered datacentre, to another form of offsets.\n",
    "\n",
    "But for now, to start with, let's try using the [Green Web API](https://www.thegreenwebfoundation.org/green-web-feed/) - the API is simple to understand, and in use.\n",
    "\n",
    "This API checks a domain against who is hosting it, and checks if the hosting company has declared they're running on renewables. It's not clear to me yet what specific checks there, and _how_ they do this, but again, it's our first pass at this.\n",
    "\n",
    "### Run this check\n",
    "\n",
    "It's not technically complex to loop through a csv file, and for each row hit an API. In python the pseudocode might look like this:\n",
    "\n",
    "```python\n",
    "\n",
    "green_or_not_list = []\n",
    "\n",
    "for row in open('path/to/dataset.csv'):\n",
    "    # do some stuff to find the right column, or tell python we're \n",
    "    # looking at a CSV file\n",
    "    site_url = pull_url_column_from(row)\n",
    "    \n",
    "    result = check_against_green_web_api(site_url)\n",
    "    green_or_not_list.push(result)\n",
    "\n",
    "```\n",
    "\n",
    "Thing is this, this involves hitting the API a million times if there are a million rows in the dataset.\n",
    "\n",
    "It's in the very least polite to contact the nice folks at Green Web before we hit their API a million times - one for each url in the Alexa dataset though.\n",
    "\n",
    "The nice thing in the dataset from Alex is that the csv file as two columns, domain and rank, we can do this with the first 10, or maybe 100 results, and get something halfway interesting back, without hosing somebody else's API.\n",
    "\n",
    "### Share Results\n",
    "\n",
    "We should really to make this reproducible.\n",
    "\n",
    "It looks like packaging this up as a [binder][] would be a good step for this. I haven't made one before, but it's worth a try, right?\n",
    "\n",
    "[binder]: https://mybinder.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
